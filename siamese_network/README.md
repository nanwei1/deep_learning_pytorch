# Siamese Network
Siamese network is a neural net architecture that takes in an input pair, propagates them through the same network with the same weights, and determine if the two inputs are similar (i.e. of the same class). It is often used in one-shot learning where there is only one or very few training examples from a class, for example facial recognition. The model attempts to learn the weights in a way that can best cluster similar inputs together while differentiate those of different classes. Siamese networks are a great tool to learn embeddings when training examples are sparse.

In this work, I implemented a siamese network with the MNIST hand-written digits dataset using a network with 2 convolutional layers and 2 fully connected layers. Contrastive loss function was used to compare the embedding pairs. Triplet loss may also be used as an alternative which will be future work.

A regular CNN of similar arthitecture is also implemented on the MNIST dataset to compare the learned embeddings with the siamese network. Because the embeddings are of dimensional 2 while the CNN classifier needs 10 outputs for classification, I designed the CNN so that before the 10-dimensional output layer, there is a 2-dimensional embedding layer with no non-linearities between them. This way, we can visualize the embeddings in 2D with a simple classifier such as logistic regression.

Credits to:
https://github.com/leimao/Siamese_Network_MNIST
https://github.com/adambielski/siamese-triplet/blob/master/datasets.py

References:
https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf
https://medium.com/@subham.tiwari186/siamese-neural-network-for-one-shot-image-recognition-paper-analysis-44cf7f0c66cb
https://weiminwang.blog/2019/03/01/whale-identification-5th-place-approach-using-siamese-networks-with-adversarial-training/


## Embeddings Generated by the CNN:
Before Training:
<p align="center"> <img src=".//results_cnn/Epoch_0.png" width="300"/> </p>
Epoch 10:
<p align="center"> <img src=".//results_cnn/Epoch_10.png" width="300"/> </p>
Epoch 20:
<p align="center"> <img src=".//results_cnn/Epoch_20.png" width="300"/> </p>
Epoch 50:
<p align="center"> <img src=".//results_cnn/Epoch_50.png" width="300"/> </p>
Applying a logistic regression model on the embeddings:
<p align="center"> <img src=".//results_cnn/Simple Classifier.png" width="300"/> </p>


## Embeddings Generated by the siamese network:
Before Training:
<p align="center"> <img src=".//results_siamese/Epoch_0.png" width="300"/> </p>
Epoch 10:
<p align="center"> <img src=".//results_siamese/Epoch_10.png" width="300"/> </p>
Epoch 20:
<p align="center"> <img src=".//results_siamese/Epoch_20.png" width="300"/> </p>
Epoch 50:
<p align="center"> <img src=".//results_siamese/Epoch_50.png" width="300"/> </p>
Applying a logistic regression model on the embeddings:
<p align="center"> <img src=".//results_siamese/Simple Classifier.png" width="300"/> </p>


Epoch 5:
<p align="center"> <img src=".//MNIST_GAN_CNN/samples/fake_images-5.png" width="300"/> </p>
Epoch 10:
<p align="center"> <img src=".//MNIST_GAN_CNN/samples/fake_images-15.png" width="300"/> </p>
Epoch 15:
<p align="center"> <img src=".//MNIST_GAN_CNN/samples/fake_images-25.png" width="300"/> </p>
Epoch 20:
<p align="center"> <img src=".//MNIST_GAN_CNN/samples/fake_images-30.png" width="300"/> </p>

